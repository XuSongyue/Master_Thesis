{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512f9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point, box\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.geometry.base import BaseGeometry\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082ed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set global font to Times New Roman\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# Constant definitions\n",
    "PROJECTED_CRS = \"EPSG:32651\"  # UTM Zone 51N\n",
    "\n",
    "# File paths\n",
    "lst_dir = \"shanghai_LST/LST\"\n",
    "landuse_shp = \"shanghai-latest-free.shp/gis_osm_landuse_a_free_1.shp\"\n",
    "water_shp = \"shanghai-latest-free.shp/gis_osm_water_a_free_1.shp\"\n",
    "places_shp = \"shanghai-latest-free.shp/gis_osm_places_a_free_1.shp\"\n",
    "traffic_shp = \"shanghai-latest-free.shp/gis_osm_traffic_a_free_1.shp\"\n",
    "pois_shp = \"shanghai-latest-free.shp/gis_osm_pois_a_free_1.shp\"\n",
    "roads_shp = \"shanghai-latest-free.shp/gis_osm_roads_free_1.shp\"\n",
    "buildings_shp = \"shanghai-latest-free.shp/gis_osm_buildings_a_free_1.shp\"\n",
    "transport_shp = \"shanghai-latest-free.shp/gis_osm_transport_a_free_1.shp\"\n",
    "boundary_path = \"OSMB-a05454319b28f099ff3da3a49c5dd21e484d8b2d.geojson\"\n",
    "output_dir = \"Results\"\n",
    "processed_dir = \"processed_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236e1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory and processed data directory exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412c6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file existence\n",
    "def check_file_exists(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File {file_path} does not exist\")\n",
    "    return file_path\n",
    "\n",
    "def process_and_save_gdf(gdf, save_path, boundary_gdf, driver=\"GeoJSON\"):\n",
    "    \"\"\"Process GeoDataFrame, convert to EPSG:4326 and clip to boundary, use GeoJSON to avoid Shapefile limitations\"\"\"\n",
    "    logger.info(f\"Original CRS: {gdf.crs}\")\n",
    "    if gdf.crs != \"EPSG:4326\":\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "    gdf = gdf[gdf.intersects(boundary_gdf.unary_union)]\n",
    "\n",
    "    # Rename column names to fit Shapefile limitations\n",
    "    if driver == \"ESRI Shapefile\":\n",
    "        gdf.columns = [col[:10] if len(col) > 10 else col for col in gdf.columns]\n",
    "\n",
    "    try:\n",
    "        gdf.to_file(save_path, driver=driver)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save {save_path}: {e}\")\n",
    "        raise\n",
    "    return gdf\n",
    "\n",
    "# Define function to load or process GeoDataFrame\n",
    "def load_or_process_gdf(raw_gdf, save_path, boundary_gdf, driver=\"GeoJSON\"):\n",
    "    \"\"\"Load processed GeoDataFrame or process and save new data\"\"\"\n",
    "    if os.path.exists(save_path):\n",
    "        try:\n",
    "            return gpd.read_file(save_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load {save_path}: {e}\")\n",
    "    logger.info(f\"Processing and saving {save_path}...\")\n",
    "    return process_and_save_gdf(raw_gdf, save_path, boundary_gdf, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c50aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shanghai boundary\n",
    "boundary_save_path = os.path.join(processed_dir, \"shanghai_boundary.geojson\")\n",
    "if os.path.exists(boundary_save_path):\n",
    "    gdf_shanghai = gpd.read_file(boundary_save_path)\n",
    "else:\n",
    "    gdf_shanghai = gpd.read_file(check_file_exists(boundary_path))\n",
    "    gdf_shanghai.to_file(boundary_save_path, driver=\"GeoJSON\")\n",
    "\n",
    "# Load various data\n",
    "gdf_landuse = gpd.read_file(check_file_exists(landuse_shp))\n",
    "gdf_water = gpd.read_file(check_file_exists(water_shp))\n",
    "gdf_places = gpd.read_file(check_file_exists(places_shp))\n",
    "gdf_traffic = gpd.read_file(check_file_exists(traffic_shp))\n",
    "gdf_pois = gpd.read_file(check_file_exists(pois_shp))\n",
    "gdf_roads = gpd.read_file(check_file_exists(roads_shp))\n",
    "gdf_buildings = gpd.read_file(check_file_exists(buildings_shp))\n",
    "gdf_transport = gpd.read_file(check_file_exists(transport_shp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc1c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Landuse fclass: ['residential' 'park' 'retail' 'commercial' 'forest' 'recreation_ground'\n",
      " 'grass' 'industrial' 'scrub' 'meadow' 'military' 'orchard' 'farmland'\n",
      " 'cemetery' 'nature_reserve' 'farmyard' 'allotments' 'quarry' 'vineyard'\n",
      " 'heath']\n",
      "INFO:__main__:Buildings type: ['commercial' 'tower' None 'skyscraper' 'church' 'hall' 'train_station'\n",
      " 'retail' 'pagoda' 'transportation' 'storage_tank' 'university'\n",
      " 'industrial' 'stadium' 'apartments' 'fire_station' 'school' 'office'\n",
      " 'roof' 'grandstand' 'residential' 'public' 'college' 'hotel'\n",
      " 'electricity' 'hospital' 'house' 'supermarket' 'dormitory' 'garages'\n",
      " 'detached' 'greenhouse' 'tent' 'no' 'manufacture' 'construction'\n",
      " 'bus_station' 'terrace' 'kindergarten' 'hut' 'theatre' 'garage' 'hangar'\n",
      " 'warehouse' 'shed' 'boathouse' 'service' 'conservatory' 'yes;roof'\n",
      " 'sports' 'civic' 'temple' 'parking' 'depot' 'gymnasium' 'farm'\n",
      " 'static_caravan' 'ruins' 'station' 'museum' 'gatehouse' 'government'\n",
      " 'gallery' 'boat' 'police' 'yes;commercial' 'mall' 'bungalow'\n",
      " 'marketplace' 'gasometer' 'data_center' 'semidetached_house' 'carport'\n",
      " 'retail;commercial' 'barracks' 'government_office' 'bunker'\n",
      " 'farm_auxiliary' 'sty' 'pavilion' 'leisure' 'bridge' 'q' 'subway']\n",
      "INFO:__main__:Landuse GDF: (20956, 5)\n",
      "INFO:__main__:Roads GDF: (189562, 11)\n",
      "INFO:__main__:Buildings GDF: (134251, 6)\n",
      "INFO:__main__:Transport GDF: (453, 5)\n",
      "INFO:__main__:Industrial GDF: (1985, 5), Bounds: [120.8672532  30.6947407 121.9515298  31.8450723]\n",
      "INFO:__main__:Factories GDF: (3875, 6), Bounds: [120.9809438  30.6984248 121.9043101  31.6036028]\n",
      "INFO:__main__:Power Plants GDF: (4342, 6), Bounds: [120.9809438  30.6984248 121.9043101  31.6036028]\n",
      "INFO:__main__:Transport GDF: (453, 5), Bounds: [120.9178666  30.7049484 122.2386751  31.6950277]\n"
     ]
    }
   ],
   "source": [
    "# Print data information\n",
    "logger.info(f\"Landuse fclass: {gdf_landuse['fclass'].unique()}\")\n",
    "logger.info(f\"Buildings type: {gdf_buildings['type'].unique()}\")\n",
    "logger.info(f\"Landuse GDF: {gdf_landuse.shape}\")\n",
    "logger.info(f\"Roads GDF: {gdf_roads.shape}\")\n",
    "logger.info(f\"Buildings GDF: {gdf_buildings.shape}\")\n",
    "logger.info(f\"Transport GDF: {gdf_transport.shape}\")\n",
    "\n",
    "# Filter relevant data\n",
    "gdf_industrial = gdf_landuse[gdf_landuse['fclass'].isin(['industrial'])].copy()\n",
    "gdf_green = gdf_landuse[gdf_landuse['fclass'].isin(['park', 'forest', 'grass'])].copy()\n",
    "gdf_water = gdf_water[gdf_water['fclass'] == 'water'].copy()\n",
    "factory_power_types = ['industrial', 'factory']\n",
    "gdf_factories = gdf_buildings[gdf_buildings['type'].isin(factory_power_types)].copy()\n",
    "energy_related_types = ['industrial', 'depot', 'storage_tank']\n",
    "gdf_power_plants = gdf_buildings[gdf_buildings['type'].isin(energy_related_types)].copy()\n",
    "\n",
    "# Validate filtering results\n",
    "logger.info(f\"Industrial GDF: {gdf_industrial.shape}, Bounds: {gdf_industrial.total_bounds if not gdf_industrial.empty else 'Empty'}\")\n",
    "logger.info(f\"Factories GDF: {gdf_factories.shape}, Bounds: {gdf_factories.total_bounds if not gdf_factories.empty else 'Empty'}\")\n",
    "logger.info(f\"Power Plants GDF: {gdf_power_plants.shape}, Bounds: {gdf_power_plants.total_bounds if not gdf_power_plants.empty else 'Empty'}\")\n",
    "logger.info(f\"Transport GDF: {gdf_transport.shape}, Bounds: {gdf_transport.total_bounds if not gdf_transport.empty else 'Empty'}\")\n",
    "\n",
    "# Process and save GeoDataFrame\n",
    "gdf_list = [\n",
    "    (\"industrial_areas.geojson\", gdf_industrial),\n",
    "    (\"green_areas.geojson\", gdf_green),\n",
    "    (\"water_bodies.geojson\", gdf_water),\n",
    "    (\"factories.geojson\", gdf_factories),\n",
    "    (\"power_plants.geojson\", gdf_power_plants),\n",
    "    (\"buildings.geojson\", gdf_buildings),\n",
    "    (\"roads.geojson\", gdf_roads),\n",
    "    (\"transport.geojson\", gdf_transport)\n",
    "]\n",
    "\n",
    "for name, raw_gdf in gdf_list:\n",
    "    save_path = os.path.join(processed_dir, name)\n",
    "    globals()[f\"gdf_{name.split('.')[0]}\"] = load_or_process_gdf(raw_gdf, save_path, gdf_shanghai, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42007695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_36172\\1976959811.py:22: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  return read_raster(file_path, gdf_shanghai.unary_union)\n",
      "INFO:__main__:LST Shape: (132, 141)\n",
      "INFO:__main__:LST Valid Pixels: 8422\n",
      "INFO:__main__:Calculated pixel size: 0.00898315284119522 meters, Manual calculated pixel size: 846.3487641583322 meters\n"
     ]
    }
   ],
   "source": [
    "# Read and clip LST raster\n",
    "def read_raster(file_path, boundary):\n",
    "    \"\"\"Read and clip raster data, return data, metadata, and transform\"\"\"\n",
    "    with rasterio.open(file_path) as src:\n",
    "        out_image, out_transform = mask(src, [boundary], crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({'height': out_image.shape[1], 'width': out_image.shape[2], 'transform': out_transform})\n",
    "        out_image = out_image.astype(np.float32)\n",
    "        out_image[out_image == src.nodata] = np.nan\n",
    "    return out_image[0], out_meta, src.meta['transform']\n",
    "\n",
    "# Extract LST data for specific year and month\n",
    "def get_lst_data(year, month):\n",
    "    \"\"\"Extract LST data for the specified year and month\"\"\"\n",
    "    year_dir = os.path.join(lst_dir, str(year))\n",
    "    if not os.path.exists(year_dir):\n",
    "        logger.warning(f\"{year_dir} does not exist\")\n",
    "        return None, None, None\n",
    "    for filename in os.listdir(year_dir):\n",
    "        if filename.endswith(\".tif\") and f\"Day{year}-{month:02d}\" in filename:\n",
    "            file_path = os.path.join(year_dir, filename)\n",
    "            return read_raster(file_path, gdf_shanghai.unary_union)\n",
    "    logger.warning(f\"No LST data found for {year}-{month:02d}\")\n",
    "    return None, None, None\n",
    "\n",
    "# Extract the latest LST data\n",
    "latest_year, latest_month = 2024, 12\n",
    "latest_lst, latest_meta, transform = get_lst_data(latest_year, latest_month)\n",
    "if latest_lst is None:\n",
    "    raise ValueError(\"Unable to load LST data, please check file path and naming\")\n",
    "\n",
    "# Print LST information\n",
    "height, width = latest_lst.shape\n",
    "logger.info(f\"LST Shape: {latest_lst.shape}\")\n",
    "logger.info(f\"LST Valid Pixels: {np.sum(~np.isnan(latest_lst))}\")\n",
    "pixel_size = abs(transform[0])  # Pixel size (meters)\n",
    "manual_pixel_size = (122.108 - 120.850) * 111000 * math.cos(math.radians(31.284)) / 141\n",
    "logger.info(f\"Calculated pixel size: {pixel_size} meters, Manual calculated pixel size: {manual_pixel_size} meters\")\n",
    "pixel_size = manual_pixel_size  # Use manual value meters/pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d5b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Adjusted BUFFER_5KM: 5 pixels, BUFFER_10KM: 11 pixels\n"
     ]
    }
   ],
   "source": [
    "# Dynamically set buffer sizes\n",
    "BUFFER_5KM = int(5000 / pixel_size)  # 5km buffer in pixels\n",
    "BUFFER_10KM = int(10000 / pixel_size)  # 10km buffer in pixels\n",
    "logger.info(f\"Adjusted BUFFER_5KM: {BUFFER_5KM} pixels, BUFFER_10KM: {BUFFER_10KM} pixels\")\n",
    "\n",
    "# Extract longitude and latitude grid\n",
    "x = np.array([transform[2] + transform[0] * j for j in range(width)])\n",
    "y = np.array([transform[5] + transform[4] * i for i in range(height)])\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(lst, meta, industrial_gdf, green_gdf, water_gdf, factories_gdf, power_plants_gdf, transport_gdf,\n",
    "                     roads_gdf, buildings_gdf, lon, lat):\n",
    "    \"\"\"\n",
    "    Extract LST and geographic features\n",
    "    \"\"\"\n",
    "    df_save_path = os.path.join(processed_dir, \"latest_df.csv\")\n",
    "    if os.path.exists(df_save_path):\n",
    "        return pd.read_csv(df_save_path)\n",
    "    \n",
    "        # Convert to projected coordinate system and validate\n",
    "    industrial_gdf_projected = industrial_gdf.to_crs(PROJECTED_CRS)\n",
    "    green_gdf_projected = green_gdf.to_crs(PROJECTED_CRS)\n",
    "    water_gdf_projected = water_gdf.to_crs(PROJECTED_CRS)\n",
    "    factories_gdf_projected = factories_gdf.to_crs(PROJECTED_CRS)\n",
    "    power_plants_gdf_projected = power_plants_gdf.to_crs(PROJECTED_CRS)\n",
    "    transport_gdf_projected = transport_gdf.to_crs(PROJECTED_CRS)\n",
    "    roads_gdf_projected = roads_gdf.to_crs(PROJECTED_CRS)\n",
    "    buildings_gdf_projected = buildings_gdf.to_crs(PROJECTED_CRS)\n",
    "\n",
    "    # Create STRtree spatial index\n",
    "    industrial_tree = STRtree(industrial_gdf_projected.geometry) if not industrial_gdf_projected.empty else None\n",
    "    green_tree = STRtree(green_gdf_projected.geometry) if not green_gdf_projected.empty else None\n",
    "    water_tree = STRtree(water_gdf_projected.geometry) if not water_gdf_projected.empty else None\n",
    "    factories_tree = STRtree(factories_gdf_projected.geometry) if not factories_gdf_projected.empty else None\n",
    "    power_plants_tree = STRtree(power_plants_gdf_projected.geometry) if not power_plants_gdf_projected.empty else None\n",
    "    transport_tree = STRtree(transport_gdf_projected.geometry) if not transport_gdf_projected.empty else None\n",
    "    roads_tree = STRtree(roads_gdf_projected.geometry) if not roads_gdf_projected.empty else None\n",
    "    buildings_tree = STRtree(buildings_gdf_projected.geometry) if not buildings_gdf_projected.empty else None\n",
    "\n",
    "    # Extract longitude, latitude, and LST data for the entire grid\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "    lst_flat = lst.ravel()\n",
    "\n",
    "    # Create point geometries\n",
    "    points = gpd.GeoSeries(\n",
    "        [Point(lon_val, lat_val) for lon_val, lat_val in zip(lon_grid.ravel(), lat_grid.ravel())],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    points_projected = points.to_crs(PROJECTED_CRS)\n",
    "    logger.info(f\"Sample Point: {points_projected[0].wkt}\")\n",
    "\n",
    "    # Initialize feature arrays\n",
    "    n_points = len(points)\n",
    "    dist_to_industrial = np.full(n_points, np.nan)\n",
    "    is_industrial = np.zeros(n_points, dtype=int)\n",
    "    factory_counts = np.zeros(n_points)\n",
    "    power_plant_flag = np.zeros(n_points, dtype=int)\n",
    "    transport_hub_flag = np.zeros(n_points, dtype=int)\n",
    "    road_counts = np.zeros(n_points)\n",
    "    building_counts = np.zeros(n_points)\n",
    "    dist_to_green = np.full(n_points, np.nan)\n",
    "    dist_to_water = np.full(n_points, np.nan)\n",
    "\n",
    "    # Buffer sizes (meters)\n",
    "    buffer_1km_m = 5000  # 5km buffer (meters)\n",
    "    buffer_5km_m = 10000  # 10km buffer (meters)\n",
    "\n",
    "    # Calculate features\n",
    "    for idx, p in enumerate(points_projected):\n",
    "        # Industrial-related features\n",
    "        if industrial_tree:\n",
    "            # Query returns indices instead of geometry objects\n",
    "            query_indices = industrial_tree.query(p.buffer(buffer_1km_m))\n",
    "            if len(query_indices) > 0:\n",
    "                # Retrieve actual geometry objects using indices\n",
    "                query_geoms = industrial_gdf_projected.geometry.iloc[query_indices]\n",
    "                logger.info(\n",
    "                    f\"Industrial Query for point {p.wkt}: {len(query_indices)} geoms found, Buffer size: {buffer_1km_m} m\")\n",
    "                is_industrial[idx] = 1 if any(p.intersects(geom) for geom in query_geoms) else 0\n",
    "\n",
    "                # Find the nearest industrial area and calculate distance\n",
    "                nearest_idx = industrial_tree.nearest(p)\n",
    "                if nearest_idx is not None:  # Ensure a nearest object is found\n",
    "                    nearest_geom = industrial_gdf_projected.geometry.iloc[nearest_idx]\n",
    "                    dist_to_industrial[idx] = p.distance(nearest_geom) / 1000  # Convert to kilometers\n",
    "\n",
    "        # Factory density\n",
    "        if factories_tree:\n",
    "            nearby_indices = factories_tree.query(p.buffer(buffer_1km_m))\n",
    "            factory_counts[idx] = len(nearby_indices)\n",
    "            logger.info(f\"Factories Query: {len(nearby_indices)} geoms found\")\n",
    "\n",
    "        # Power plants and transport hubs\n",
    "        if power_plants_tree:\n",
    "            query_indices = power_plants_tree.query(p.buffer(buffer_5km_m))\n",
    "            logger.info(f\"Power Plants Query: {len(query_indices)} geoms found\")\n",
    "            if len(query_indices) > 0:\n",
    "                # Retrieve all queried geometry objects\n",
    "                query_geoms = power_plants_gdf_projected.geometry.iloc[query_indices]\n",
    "                # Calculate minimum distance\n",
    "                distances = [p.distance(geom) for geom in query_geoms]\n",
    "                if distances:\n",
    "                    nearest_dist = min(distances)\n",
    "                    power_plant_flag[idx] = 1 if nearest_dist < buffer_5km_m else 0\n",
    "\n",
    "        if transport_tree:\n",
    "            query_indices = transport_tree.query(p.buffer(buffer_5km_m))\n",
    "            logger.info(f\"Transport Query: {len(query_indices)} geoms found\")\n",
    "            if len(query_indices) > 0:\n",
    "                # Retrieve all queried geometry objects\n",
    "                query_geoms = transport_gdf_projected.geometry.iloc[query_indices]\n",
    "                # Calculate minimum distance\n",
    "                distances = [p.distance(geom) for geom in query_geoms]\n",
    "                if distances:\n",
    "                    nearest_dist = min(distances)\n",
    "                    transport_hub_flag[idx] = 1 if nearest_dist < buffer_5km_m else 0\n",
    "\n",
    "        # Roads and buildings\n",
    "        if roads_tree:\n",
    "            nearby_indices = roads_tree.query(p.buffer(buffer_1km_m))\n",
    "            road_counts[idx] = len(nearby_indices)\n",
    "\n",
    "        if buildings_tree:\n",
    "            nearby_indices = buildings_tree.query(p.buffer(buffer_1km_m))\n",
    "            building_counts[idx] = len(nearby_indices)\n",
    "\n",
    "        # Green areas and water bodies\n",
    "        if green_tree:\n",
    "            nearest_idx = green_tree.nearest(p)\n",
    "            if nearest_idx is not None:\n",
    "                nearest_geom = green_gdf_projected.geometry.iloc[nearest_idx]\n",
    "                dist_to_green[idx] = p.distance(nearest_geom) / 1000  # Convert to kilometers\n",
    "\n",
    "        if water_tree:\n",
    "            nearest_idx = water_tree.nearest(p)\n",
    "            if nearest_idx is not None:\n",
    "                nearest_geom = water_gdf_projected.geometry.iloc[nearest_idx]\n",
    "                dist_to_water[idx] = p.distance(nearest_geom) / 1000  # Convert to kilometers\n",
    "\n",
    "    # Calculate density and impervious surface ratio\n",
    "    buffer_areas = points_projected.buffer(buffer_1km_m).area\n",
    "    factory_density = factory_counts / (buffer_areas / 1e6)  # Factories per square kilometer\n",
    "    road_density = road_counts / (buffer_areas / 1e6)  # Roads per square kilometer\n",
    "    impervious_ratio = (road_counts + building_counts) / (buffer_areas / 1e6 * 1000)  # Impervious surface ratio\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'lst': lst_flat,\n",
    "        'lon': lon_grid.ravel(),\n",
    "        'lat': lat_grid.ravel(),\n",
    "        'dist_to_industrial': dist_to_industrial,\n",
    "        'is_industrial': is_industrial,\n",
    "        'factory_density': factory_density,\n",
    "        'power_plant_flag': power_plant_flag,\n",
    "        'transport_hub_flag': transport_hub_flag,\n",
    "        'road_density': road_density,\n",
    "        'impervious_ratio': impervious_ratio,\n",
    "        'dist_to_green': dist_to_green,\n",
    "        'dist_to_water': dist_to_water\n",
    "    }).dropna(subset=['lst'])\n",
    "\n",
    "    try:\n",
    "        df.to_csv(df_save_path, index=False)\n",
    "        logger.info(f\"Successfully saved DataFrame to {df_save_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save DataFrame: {e}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3056e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "latest_df = extract_features(latest_lst, latest_meta, gdf_industrial, gdf_green, gdf_water, gdf_factories,\n",
    "                             gdf_power_plants, gdf_transport, gdf_roads, gdf_buildings, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2573814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate industrial land density\n",
    "industrial_density = np.zeros_like(latest_lst)\n",
    "for idx, row in latest_df.iterrows():\n",
    "    if row['is_industrial'] == 1:\n",
    "        i = np.searchsorted(y, row['lat'], side='right') - 1\n",
    "        j = np.searchsorted(x, row['lon'], side='right') - 1\n",
    "        if 0 <= i < height and 0 <= j < width:\n",
    "            industrial_density[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6cd00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getis-Ord Gi* statistic\n",
    "def calculate_getis_ord_gi_star(data, lat, lon, dist_threshold=0.02):\n",
    "    \"\"\"Calculate Getis-Ord Gi* statistic to identify hotspots\"\"\"\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "    points = np.column_stack((lat_grid.ravel(), lon_grid.ravel()))\n",
    "    data_flat = data.ravel()\n",
    "    valid_mask = ~np.isnan(data_flat)\n",
    "    data_flat, points = data_flat[valid_mask], points[valid_mask]\n",
    "    n = len(data_flat)\n",
    "    mean_x, std_x = np.mean(data_flat), np.std(data_flat)\n",
    "    Gi_star = np.full(n, np.nan)\n",
    "    for i, point in enumerate(points):\n",
    "        distances = np.sqrt(((points - point) ** 2).sum(axis=1))\n",
    "        neighbors = distances <= dist_threshold\n",
    "        local_sum = np.sum(data_flat[neighbors])\n",
    "        weight_sum = np.sum(neighbors)\n",
    "        weight_sq_sum = np.sum(neighbors ** 2)\n",
    "        numerator = local_sum - mean_x * weight_sum\n",
    "        denominator = std_x * np.sqrt((n * weight_sq_sum - weight_sum ** 2) / (n - 1)) if n > 1 else 1\n",
    "        Gi_star[i] = numerator / denominator if denominator != 0 else 0\n",
    "    Gi_star_grid = np.full(lat_grid.shape, np.nan)\n",
    "    Gi_star_grid.ravel()[valid_mask] = Gi_star\n",
    "    return Gi_star_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4086b853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:LST data range: (120.85035517259927, 30.695433258364066, 122.1079965703666, 31.87222628056064)\n",
      "INFO:__main__:Number of filtered Shanghai boundary parts: 1\n"
     ]
    }
   ],
   "source": [
    "# Calculate UHI and industrial hotspots\n",
    "lst_gi_star = calculate_getis_ord_gi_star(latest_lst, y, x, dist_threshold=0.02)\n",
    "industrial_gi_star = calculate_getis_ord_gi_star(industrial_density, y, x, dist_threshold=0.02)\n",
    "\n",
    "# Determine LST data range\n",
    "lst_bounds = box(min(x.flatten()), min(y.flatten()), max(x.flatten()), max(y.flatten()))\n",
    "logger.info(f\"LST data range: {lst_bounds.bounds}\")\n",
    "\n",
    "# Convert LST range to GeoDataFrame for spatial filtering\n",
    "lst_bounds_gdf = gpd.GeoDataFrame(geometry=[lst_bounds], crs=\"EPSG:4326\")\n",
    "\n",
    "# Ensure gdf_shanghai's CRS matches LST data (EPSG:4326)\n",
    "if gdf_shanghai.crs != \"EPSG:4326\":\n",
    "    gdf_shanghai = gdf_shanghai.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Filter gdf_shanghai for parts intersecting LST data range\n",
    "gdf_shanghai_subset = gdf_shanghai[gdf_shanghai.intersects(lst_bounds)]\n",
    "logger.info(f\"Number of filtered Shanghai boundary parts: {len(gdf_shanghai_subset)}\")\n",
    "\n",
    "# Log warning if gdf_shanghai_subset is empty\n",
    "if gdf_shanghai_subset.empty:\n",
    "    logger.warning(\"No Shanghai boundary parts intersecting LST data range found!\")\n",
    "\n",
    "# Plot UHI and industrial hotspots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "im1 = ax1.pcolormesh(x, y, lst_gi_star, cmap=\"RdBu\", shading=\"auto\")\n",
    "ax1.set_title(\"UHI Hotspot (Gi*)\", fontsize=14)\n",
    "plt.colorbar(im1, ax=ax1, label=\"Gi*\")\n",
    "if not gdf_shanghai_subset.empty:\n",
    "    gdf_shanghai_subset.boundary.plot(ax=ax1, color=\"black\", linewidth=1)\n",
    "\n",
    "im2 = ax2.pcolormesh(x, y, industrial_gi_star, cmap=\"YlOrRd\", shading=\"auto\")\n",
    "ax2.set_title(\"Industrial Hotspot (Gi*)\", fontsize=14)\n",
    "plt.colorbar(im2, ax=ax2, label=\"Gi*\")\n",
    "if not gdf_shanghai_subset.empty:\n",
    "    gdf_shanghai_subset.boundary.plot(ax=ax2, color=\"black\", linewidth=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"uhi_industrial_hotspots.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Visualize hotspot areas and industrial zones\n",
    "plt.figure(figsize=(10, 8))\n",
    "latest_df['is_hotspot'] = latest_df['lst'] > latest_df['lst'].quantile(0.70)\n",
    "plt.scatter(latest_df['lon'], latest_df['lat'], c=latest_df['is_hotspot'], cmap='Reds', s=1)\n",
    "if not gdf_industrial.empty:\n",
    "    # Filter gdf_industrial for parts intersecting LST range\n",
    "    gdf_industrial_subset = gdf_industrial[gdf_industrial.intersects(lst_bounds)]\n",
    "    if not gdf_industrial_subset.empty:\n",
    "        gdf_industrial_subset.boundary.plot(ax=plt.gca(), color='blue', linewidth=1)\n",
    "    else:\n",
    "        logger.warning(\"No industrial zones intersecting LST data range found!\")\n",
    "plt.title(\"Industrial & UHI\")\n",
    "plt.savefig(os.path.join(output_dir, 'hotspot_industrial.png'), dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44648523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Number of hotspot pixels: 2527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrial land proportion in hotspot areas: 11.40%\n",
      "Factory density in hotspot areas: 1.6298 factories/km²\n",
      "Coal power plant proportion in hotspot areas: 97.15%\n",
      "Transport hub proportion in hotspot areas: 92.40%\n",
      "Impervious surface ratio in hotspot areas: 7.36%\n",
      "Distance to green areas in hotspot areas: 1.0559 km\n",
      "Distance to water bodies in hotspot areas: 1.1236 km\n"
     ]
    }
   ],
   "source": [
    "# Industrial feature analysis within hotspot areas\n",
    "hotspot_df = latest_df[latest_df['is_hotspot']]\n",
    "logger.info(f\"Number of hotspot pixels: {latest_df['is_hotspot'].sum()}\")\n",
    "print(f\"Industrial land proportion in hotspot areas: {hotspot_df['is_industrial'].mean():.2%}\")\n",
    "print(f\"Factory density in hotspot areas: {hotspot_df['factory_density'].mean():.4f} factories/km²\")\n",
    "print(f\"Coal power plant proportion in hotspot areas: {hotspot_df['power_plant_flag'].mean():.2%}\")\n",
    "print(f\"Transport hub proportion in hotspot areas: {hotspot_df['transport_hub_flag'].mean():.2%}\")\n",
    "print(f\"Impervious surface ratio in hotspot areas: {hotspot_df['impervious_ratio'].mean():.2%}\")\n",
    "print(f\"Distance to green areas in hotspot areas: {hotspot_df['dist_to_green'].mean():.4f} km\")\n",
    "print(f\"Distance to water bodies in hotspot areas: {hotspot_df['dist_to_water'].mean():.4f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70c76da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training set size: 6737, Test set size: 1685\n"
     ]
    }
   ],
   "source": [
    "# Machine learning analysis\n",
    "# Define features and target for classification\n",
    "features = ['dist_to_industrial', 'is_industrial', 'factory_density', 'power_plant_flag',\n",
    "            'transport_hub_flag', 'road_density', 'impervious_ratio', 'dist_to_green', 'dist_to_water']\n",
    "X = latest_df[features]\n",
    "y = latest_df['is_hotspot'].astype(int)  # Binary classification: 1 (hotspot), 0 (non-hotspot)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "logger.info(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba872737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]  # Probabilities for RMSE and R²\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # Probabilities for RMSE and R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea2e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier - Accuracy: 0.79, Precision: 0.71, Recall: 0.51, F1-Score: 0.60\n",
      "Random Forest Classifier - RMSE (using probabilities): 0.38, R²: 0.32\n",
      "XGBoost Classifier - Accuracy: 0.78, Precision: 0.67, Recall: 0.54, F1-Score: 0.59\n",
      "XGBoost Classifier - RMSE (using probabilities): 0.38, R²: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models - Classification metrics\n",
    "def evaluate_classification_model(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{model_name} - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate models - Regression-like metrics (using probabilities)\n",
    "def evaluate_regression_metrics(y_true, y_pred_proba, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred_proba))\n",
    "    r2 = r2_score(y_true, y_pred_proba)\n",
    "    print(f\"{model_name} - RMSE (using probabilities): {rmse:.2f}, R²: {r2:.2f}\")\n",
    "    return rmse, r2\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_metrics = evaluate_classification_model(y_test, rf_pred, \"Random Forest Classifier\")\n",
    "rf_rmse, rf_r2 = evaluate_regression_metrics(y_test, rf_pred_proba, \"Random Forest Classifier\")\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_metrics = evaluate_classification_model(y_test, xgb_pred, \"XGBoost Classifier\")\n",
    "xgb_rmse, xgb_r2 = evaluate_regression_metrics(y_test, xgb_pred_proba, \"XGBoost Classifier\")\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Non-Hotspot', 'Hotspot'], yticklabels=['Non-Hotspot', 'Hotspot'])\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('Actual', fontsize=12)\n",
    "    plt.savefig(os.path.join(output_dir, f'confusion_matrix_{model_name.lower().replace(\" \", \"_\")}.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrix(y_test, rf_pred, \"Random Forest Classifier\")\n",
    "plot_confusion_matrix(y_test, xgb_pred, \"XGBoost Classifier\")\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "rf_importance = pd.DataFrame({'feature': features, 'importance': rf_model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=rf_importance)\n",
    "plt.title('Feature Importance - Random Forest Classifier', fontsize=14)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.savefig(os.path.join(output_dir, 'feature_importance_rf_classifier.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Feature Importance for XGBoost\n",
    "xgb_importance = pd.DataFrame({'feature': features, 'importance': xgb_model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=xgb_importance)\n",
    "plt.title('Feature Importance - XGBoost Classifier', fontsize=14)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.savefig(os.path.join(output_dir, 'feature_importance_xgb_classifier.png'), dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1f566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
